{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d8f3ef6",
   "metadata": {},
   "source": [
    "# Identifying Events\n",
    "\n",
    "This script takes netCDF files with daily wind and RH measurements and identifies strong wind events, filters them by RH to find dry wind events, and aggregates those events into summary grids describing event statistics such as median duration, magnitude, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9e0541",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T01:57:26.097090Z",
     "start_time": "2022-02-17T01:57:25.252860Z"
    }
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.signal\n",
    "import geopandas as gpd\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34c6607",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T01:57:26.099086Z",
     "start_time": "2022-02-17T01:57:25.490Z"
    }
   },
   "outputs": [],
   "source": [
    "# Keep attributes by default, such as when performing mathematical operations on DataArrays\n",
    "# https://github.com/pydata/xarray/pull/2482\n",
    "xr.set_options(keep_attrs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b303dbf9",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca96d95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T17:52:54.106959Z",
     "start_time": "2021-07-14T17:52:54.093013Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_no_data_around_indexes(arr, indexes):\n",
    "    def get_inverse_mask(arr, unmasked_indexes):\n",
    "        \"\"\"Generate a boolean mask for a 1D array masked at all indexes except for the unmasked indexes.\n",
    "        \"\"\"\n",
    "        mask = np.ones(arr.shape[0], dtype=bool)\n",
    "        mask.put(unmasked_indexes, 0)\n",
    "        return mask\n",
    "    \n",
    "    mask = get_inverse_mask(arr, indexes)\n",
    "    output = arr.copy()\n",
    "    output[mask] = np.nan\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4b003b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T17:52:54.494976Z",
     "start_time": "2021-07-14T17:52:54.486997Z"
    }
   },
   "outputs": [],
   "source": [
    "def peak_magnitude_mask_duration_prominence(arr, **kwargs):\n",
    "    peak_indexes = scipy.signal.find_peaks(arr, **kwargs)[0]\n",
    "    \n",
    "    peak_prominence = scipy.signal.peak_prominences(arr, peak_indexes)\n",
    "    peak_widths = scipy.signal.peak_widths(arr, peak_indexes, prominence_data=peak_prominence)[0]\n",
    "    \n",
    "    presence_mask = arr.copy()\n",
    "    presence_mask[peak_indexes] = 1\n",
    "    \n",
    "    widths = arr.copy()\n",
    "    widths[peak_indexes] = peak_widths\n",
    "    \n",
    "    prominence = arr.copy()\n",
    "    prominence[peak_indexes] = peak_prominence[0]\n",
    "    \n",
    "    prominence_out = set_no_data_around_indexes(prominence, peak_indexes)\n",
    "    presence_out = set_no_data_around_indexes(presence_mask, peak_indexes)\n",
    "    duration_out = set_no_data_around_indexes(widths, peak_indexes)\n",
    "    magnitude_out = set_no_data_around_indexes(arr, peak_indexes)\n",
    "    \n",
    "    return magnitude_out, presence_out, duration_out, prominence_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a906c45b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T17:52:55.008466Z",
     "start_time": "2021-07-14T17:52:54.986968Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_wind_event_stats(dataset, wind, rh, rh_threshold=36, wind_threshold=4, min_spacing=5, min_duration=1):\n",
    "    \"\"\"Take an xarray.Dataset and append variables describing wind event stats at event peaks.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : xarray.Dataset\n",
    "        The dataset to calculate events from.\n",
    "    wind : str\n",
    "        The name of the wind variable in the dataset.\n",
    "    rh : str\n",
    "        The name of the relative humidity variable in the dataset.\n",
    "    rh_threshold : int\n",
    "        The maximum RH to be considered an event.\n",
    "    \"\"\"\n",
    "    output = dataset.copy()\n",
    "    \n",
    "    # Generate grids with event data at each peak\n",
    "    magnitude, mask, duration, prominence = np.apply_along_axis(peak_magnitude_mask_duration_prominence, 0, output[wind].values, \n",
    "                                                            height=wind_threshold, distance=min_spacing, width=min_duration)\n",
    "    \n",
    "    output = output.assign({\n",
    "        \"magnitude\": ([\"date\", \"y\", \"x\"], magnitude),\n",
    "        \"mask\": ([\"date\", \"y\", \"x\"], mask),\n",
    "        \"duration\": ([\"date\", \"y\", \"x\"], duration),\n",
    "        \"prominence\": ([\"date\", \"y\", \"x\"], prominence),        \n",
    "    })\n",
    "    \n",
    "    attrs = dataset.attrs\n",
    "\n",
    "    # Mask all event data where the peak RH is below the threshold\n",
    "    output[\"magnitude\"] = output.magnitude.where(cond=output[rh] < rh_threshold, other=np.nan).assign_attrs(attrs)\n",
    "    output[\"mask\"] = output.mask.where(cond=output[rh] < rh_threshold, other=np.nan).assign_attrs(attrs)\n",
    "    output[\"duration\"] = output.duration.where(cond=output[rh] < rh_threshold, other=np.nan).assign_attrs(attrs)\n",
    "    output[\"prominence\"] = output.prominence.where(cond=output[rh] < rh_threshold, other=np.nan).assign_attrs(attrs)\n",
    "    \n",
    "    x = output.dims[\"x\"]\n",
    "    y = output.dims[\"y\"]\n",
    "\n",
    "    days = output.date.dt.dayofyear.values\n",
    "    # Build an array the same shape as the output variables that just contains the day of the year\n",
    "    day_arr = np.repeat(days, x*y).reshape((len(days), y, x))\n",
    "\n",
    "    output = output.assign({\n",
    "        \"dayofyear\": ((\"date\", \"y\", \"x\"), day_arr)\n",
    "    })\n",
    "\n",
    "    # Mask using the pre-masked peaks\n",
    "    output[\"dayofyear\"] = output.dayofyear.where(cond=~xr.ufuncs.isnan(output.mask), other=np.nan).assign_attrs(attrs)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d78267",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T17:52:55.613610Z",
     "start_time": "2021-07-14T17:52:55.605127Z"
    }
   },
   "outputs": [],
   "source": [
    "def summarize_wind_event_stats(dataset):\n",
    "    \"\"\"Take an xarray.Dataset created by calculate_wind_event_stats and output a Dataset with wind event stats \n",
    "    summarized over time.\n",
    "    \"\"\"\n",
    "    summary_arrs = [\n",
    "        # Percent of all days within an event\n",
    "        (dataset.mask.sum(\"date\", keep_attrs=True) / dataset.dims[\"date\"]) * 100,\n",
    "        # Median duration\n",
    "        dataset.duration.median(\"date\", keep_attrs=True),\n",
    "        # Cumulative duration\n",
    "        dataset.duration.sum(\"date\", keep_attrs=True),\n",
    "        # Median magnitude\n",
    "        dataset.magnitude.median(\"date\", keep_attrs=True),\n",
    "        # Max magnitude\n",
    "        dataset.magnitude.max(\"date\", keep_attrs=True),\n",
    "        # Median day of year\n",
    "        dataset.dayofyear.median(\"date\", keep_attrs=True),\n",
    "    ]\n",
    "\n",
    "    summary_arr_names = [\n",
    "        \"percent_of_days\",\n",
    "        \"duration_median\",\n",
    "        \"duration_cumulative\",\n",
    "        \"magnitude_median\",\n",
    "        \"magnitude_max\",\n",
    "        \"dayofyear_median\",\n",
    "    ]\n",
    "\n",
    "    # When these are imported with rasterio, they get one attribute per day. Since we're switching from many days to just\n",
    "    # one, we need to just have one attribute per.\n",
    "    for arr in summary_arrs:\n",
    "        arr.attrs[\"scales\"] = np.array(arr.attrs[\"scales\"][0])\n",
    "        arr.attrs[\"offsets\"] = np.array(arr.attrs[\"offsets\"][0])\n",
    "\n",
    "    summaries = {name:arr for arr, name in zip(summary_arrs, summary_arr_names)}\n",
    "\n",
    "    # Combine summaries into 1 dataset\n",
    "    summary = xr.Dataset(summaries)\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ce5592",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T19:08:31.177299Z",
     "start_time": "2021-07-14T19:08:31.155361Z"
    }
   },
   "outputs": [],
   "source": [
    "def identify_regional_events(data, wind, rh, rolling_width=3, wind_threshold=4, min_spacing=3, min_duration=0, min_prominence=2, rh_threshold=36, min_date=121, max_date=305):\n",
    "    \"\"\"Take a Dataset that's been averaged over x and y to create a 1D timeline. Identify events and return a \n",
    "    dataframe of peaks and associated data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : xarray.Dataset\n",
    "        The regionally averaged data with only a date dimension\n",
    "    wind : str\n",
    "        Name of the wind column to use.\n",
    "    rh : str\n",
    "        Name of the relative humididty column to use.\n",
    "    min_date : int, default 121 (May 1)\n",
    "        Earliest day of the year to consider a peak. Used to limit within the burning season.\n",
    "    max_date : int, default 305 (Nov 1)\n",
    "        Latest day of the year to consider a peak. Used to limit within the burning season.\n",
    "    \"\"\"\n",
    "    data = data.copy().to_pandas().reset_index()\n",
    "\n",
    "    # Calculate a rolling average of HDW to smooth events\n",
    "    data[wind] = data[wind].rolling(window=rolling_width, center=True).mean()\n",
    "    data[rh] = data[rh].rolling(window=rolling_width, center=True).mean()\n",
    "\n",
    "    peak_indexes = scipy.signal.find_peaks(data[wind], \n",
    "                                           height=wind_threshold, \n",
    "                                           distance=min_spacing, \n",
    "                                           width=min_spacing, \n",
    "                                           prominence=min_prominence)[0]\n",
    "\n",
    "    peaks = data.iloc[peak_indexes].copy()\n",
    "    peak_widths = scipy.signal.peak_widths(data[wind], peak_indexes)\n",
    "    peaks[\"width\"] = peak_widths[0]\n",
    "\n",
    "    # Create an index column that can be used in calculations\n",
    "    peaks = peaks.reset_index()\n",
    "\n",
    "    # Identify the number of days from the center of the event to the start (left) and end (right), rounded to nearest hour\n",
    "    peaks[\"left_offset\"] = pd.to_timedelta((peaks[\"index\"] - peak_widths[2]).values, unit=\"day\").round(freq=\"h\")\n",
    "    peaks[\"right_offset\"] = pd.to_timedelta((peak_widths[3] - peaks[\"index\"]).values, unit=\"day\").round(freq=\"h\")\n",
    "    peaks[\"left\"] = peaks.date - peaks.left_offset\n",
    "    peaks[\"right\"] = peaks.date + peaks.right_offset\n",
    "\n",
    "    peaks = peaks[peaks[rh].lt(rh_threshold)]\n",
    "\n",
    "    peaks = peaks[peaks.date.dt.dayofyear.gt(min_date) & peaks.date.dt.dayofyear.lt(max_date)]\n",
    "    \n",
    "    return peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf78d865",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T17:57:31.798514Z",
     "start_time": "2021-07-14T17:57:31.780988Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_regional_peaks(data, peaks, wind, rolling_width=3, highlight_events=False):\n",
    "    \"\"\"Plot 1D wind data and associated peaks.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : xarray.Dataset\n",
    "    \n",
    "    peaks : pandas.DataFrame\n",
    "        Created by identify_regional_events.\n",
    "    \"\"\"\n",
    "    data = data.copy().to_pandas().reset_index()\n",
    "\n",
    "    # Calculate a rolling average of HDW to smooth events\n",
    "    data[wind] = data[wind].rolling(window=rolling_width, center=True).mean()\n",
    "    \n",
    "    fig = px.line(data, x=\"date\", y=wind, labels={wind: \"Wind Velocity (m/s)\", \"date\": \"\"})\n",
    "    fig.add_trace(go.Scattergl(x=peaks.date, y=peaks[wind], mode=\"markers\", name=\"Wind Peak\"))\n",
    "    \n",
    "    if highlight_events:\n",
    "        for _, peak in peaks.iterrows():\n",
    "            fig.add_vrect(x0=peak.left, x1=peak.right, fillcolor=\"red\", opacity=0.2, layer=\"below\", line_width=0)\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b7966f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T17:57:53.678047Z",
     "start_time": "2021-07-14T17:57:53.665119Z"
    }
   },
   "outputs": [],
   "source": [
    "def above_percentile_mask(arr, p=0.95):\n",
    "    \"\"\"Take a 3D array of weather values over time and mask all values less than a given percentile.\n",
    "    \"\"\"\n",
    "    threshold = np.nanquantile(arr, p, axis=[1, 2])\n",
    "    \n",
    "    x = arr.shape[2]\n",
    "    y = arr.shape[1]\n",
    "\n",
    "    # Build an array the same shape as the output variables that just contains the percentile threshold\n",
    "    threshold_arr = np.repeat(threshold, x*y).reshape((len(arr), y, x))\n",
    "\n",
    "    # Mask using the percentile threshold\n",
    "    return np.where(arr > threshold_arr, 1, np.nan)\n",
    "\n",
    "def below_percentile_mask(arr, p=0.05):\n",
    "    \"\"\"Take a 3D array of weather values over time and mask all values greater than a given percentile.\n",
    "    \"\"\"\n",
    "    threshold = np.nanquantile(arr, p, axis=[1, 2])\n",
    "    \n",
    "    x = arr.shape[2]\n",
    "    y = arr.shape[1]\n",
    "\n",
    "    # Build an array the same shape as the output variables that just contains the percentile threshold\n",
    "    threshold_arr = np.repeat(threshold, x*y).reshape((len(arr), y, x))\n",
    "\n",
    "    # Mask using the percentile threshold\n",
    "    return np.where(arr < threshold_arr, 1, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bb9d90",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2e25b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T17:52:58.015095Z",
     "start_time": "2021-07-14T17:52:57.999167Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.join(\"..\", \"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1260e274",
   "metadata": {},
   "source": [
    "## AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4949072",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T17:52:59.156913Z",
     "start_time": "2021-07-14T17:52:58.730188Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load Northwest Forest Plan boundary\n",
    "nwfp_path = os.path.join(data_dir, \"NWFP\", \"nwfpbnd.shp\")\n",
    "nwfp = gpd.read_file(nwfp_path)\n",
    "nwfp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0dbf93",
   "metadata": {},
   "source": [
    "## gridMET Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3424dadb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T18:46:53.112102Z",
     "start_time": "2021-07-14T18:46:42.220302Z"
    }
   },
   "outputs": [],
   "source": [
    "gridmet = xr.open_dataset(os.path.join(data_dir, \"gridMET\", \"gridMET.nc\"))\n",
    "\n",
    "\n",
    "gridmet = gridmet.drop(\"spatial_ref\")\n",
    "\n",
    "# Mask before calculating regional stats or percentiles to avoid including irrelevant areas\n",
    "gridmet = gridmet.rio.clip(nwfp.geometry)\n",
    "\n",
    "daily_medians_gridmet = gridmet[[\"vs\", \"rmin\"]].median([\"x\", \"y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848ad5b7",
   "metadata": {},
   "source": [
    "### Pixel-wise events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5868e8",
   "metadata": {},
   "source": [
    "Identify wind events and generate summaries of event statistics through time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6867f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-14T18:47:53.711164Z",
     "start_time": "2021-07-14T18:46:53.113103Z"
    }
   },
   "outputs": [],
   "source": [
    "# Just select summer months\n",
    "gridmet = gridmet.sel(date=gridmet.date.dt.month.isin([5, 6, 7, 8, 9, 10]))\n",
    "\n",
    "gridmet = calculate_wind_event_stats(gridmet, wind=\"vs\", rh=\"rmin\")\n",
    "gridmet_summary = summarize_wind_event_stats(gridmet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f9ec53",
   "metadata": {},
   "source": [
    "Export the summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e765bd98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T22:56:47.690848Z",
     "start_time": "2021-07-09T22:56:47.598067Z"
    }
   },
   "outputs": [],
   "source": [
    "gridmet_summary.rio.to_raster(os.path.join(data_dir, \"summary_may-oct_gridMET.tif\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geostats",
   "language": "python",
   "name": "geostats"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
